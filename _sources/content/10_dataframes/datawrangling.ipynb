{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Wrangling behavorial data generated by OpenSesame\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "You build the experiment and ran your first two participants. Now, it is time to take a look at the data you have collected. We will be working with a dataset of a task-switching study. In this study, the participants had to conduct two tasks separately: they either had to specify with the left or right button whether the number on screen was odd or even (parity task) or they had to specify with the left or right button whether the number was smaller or larger than 5 (magnitude task). The catch is that they were only told which task they had to do 500 milliseconds before the number came on screen on which they had to respond. If they had to repeat the task from the previous trial, we call that a **repeat trial**. If they had to switch to another task relative to the previous trial, we call that a **switch trial**. See below for a schematic overview of the experiment:\n",
    "\n",
    "![image info](./images/task_design_figure.png)\n",
    "\n",
    "Each participant goes through two sessions. In one session, they have to switch tasks 75% of the time (high-switch condition). In the other session, they have to switch tasks 25% of the time (low-switch condition). This setup allows us to examine what happens when people have to switch tasks: are they faster or slower? And what happens with their response time when they have to switch tasks a lot? Or very little? Let's find out.\n",
    "\n",
    "OpenSesame outputs a *comma-separated values (csv)* file. This is a very widely used format, and you can painlessly import this file type in Python using the datafile package **pandas** (as we've seen in the exercises and lessons). Let's import a datafile from two participants and merge those in one file:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# disable chained assignments, you can ignore this line of code\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# define all the subjects to load in\n",
    "subjects = [3, 4]\n",
    "\n",
    "# make an empty list where we store each URL\n",
    "url_list = []\n",
    "\n",
    "# loop over every raw file URL and store that URL in the url_list list\n",
    "for i in subjects:\n",
    "    url = 'https://raw.githubusercontent.com/JeshuaT/Experimentation1/main/content/10_dataframes/data/subject-' + str(i) + '.csv'\n",
    "    url_list.append(url)\n",
    "\n",
    "# read the csv files from the URLs and append in a pandas dataframe\n",
    "df = pd.concat((pd.read_csv(url) for url in url_list), ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's a lot of columns. In your \"logger\" file in OpenSesame, the recommended thing to do is to check the box of \"Log all variables\". This is the safest option, because it's easy to remove columns and you would rather not have that you missed an essential variable after doing your experiment. Let's pick the columns that we need:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_nr  block    session congruency_transition_type congruency_type  \\\n",
      "0           3      1  lowswitch                        NaN     incongruent   \n",
      "1           3      1  lowswitch          congruency-switch       congruent   \n",
      "2           3      1  lowswitch      congruency-repetition       congruent   \n",
      "3           3      1  lowswitch          congruency-switch     incongruent   \n",
      "4           3      1  lowswitch      congruency-repetition     incongruent   \n",
      "\n",
      "   correct  response_time task_transition_type  task_type response  \n",
      "0        0      1482.9738                  NaN     parity     None  \n",
      "1        1       706.7057          task-switch  magnitude        a  \n",
      "2        1       855.6105          task-switch     parity        a  \n",
      "3        1       867.8947      task-repetition     parity        a  \n",
      "4        1      1078.9412          task-switch  magnitude        a  \n"
     ]
    }
   ],
   "source": [
    "# make a list of column names that we want to include\n",
    "include_columns = ['subject_nr', 'block', 'session', 'congruency_transition_type', 'congruency_type',\n",
    "                   'correct', 'response_time', 'task_transition_type', 'task_type', 'response']\n",
    "\n",
    "# make a new df, called df_trim, that only included the columns that are in the \"include_columns\" list\n",
    "df_trim = df[include_columns]\n",
    "\n",
    "# it's always good practice to check the head and/or tail of a dataframe after making/changing it\n",
    "print(df_trim.head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we make any changes to the dataframe, we must first be sure that all the columns are in the right [type](https://pbpython.com/pandas_dtypes.html). If we print the data types of each column, we can see that subject_nr is an integer. However, we don't intend for the dataframe to interpret \"3\" and \"4\" as numbers, since it's simply a categorization. Let's change that:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column types BEFORE changing: \n",
      " subject_nr                    category\n",
      "block                            int64\n",
      "session                         object\n",
      "congruency_transition_type      object\n",
      "congruency_type                 object\n",
      "correct                       category\n",
      "response_time                  float64\n",
      "task_transition_type            object\n",
      "task_type                       object\n",
      "response                        object\n",
      "dtype: object \n",
      "\n",
      "Column types AFTER changing: \n",
      " subject_nr                    category\n",
      "block                            int64\n",
      "session                         object\n",
      "congruency_transition_type      object\n",
      "congruency_type                 object\n",
      "correct                       category\n",
      "response_time                  float64\n",
      "task_transition_type            object\n",
      "task_type                       object\n",
      "response                        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Column types BEFORE changing: \\n\", df_trim.dtypes, \"\\n\")\n",
    "\n",
    "df_trim['subject_nr'] = df_trim['subject_nr'].astype('category')\n",
    "df_trim['correct'] = df_trim['correct'].astype('category')\n",
    "\n",
    "print(\"Column types AFTER changing: \\n\",df_trim.dtypes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Furthermore, the response times are now rounded in the ten-thousandths (four decimal places) of milliseconds. That gives false confidence in our accuracy with measuring response times, which is more in the range of whole milliseconds. Let's change that using the pandas round function:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0      1483\n1       707\n2       856\n3       868\n4      1079\n       ... \n947     699\n948     583\n949     731\n950     438\n951    1006\nName: response_time, Length: 952, dtype: int32"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round the response time column and replace the unrounded column values with the rounded column values\n",
    "df_trim['response_time'] = df_trim['response_time'].round()\n",
    "\n",
    "# change type of the column to \"int\" instead of \"float\". \"int\" is for whole numbers, \"float\" is for numbers with decimals.\n",
    "df_trim['response_time'] = df_trim['response_time'].astype(int)\n",
    "\n",
    "# check if it worked\n",
    "df_trim['response_time']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alright, it's getting a bit more uncluttered now. The task-design is so that the last two blocks are different kind of blocks. We don't have to go in details now, but for further analysis we will have to create a dataframe without block 11 and 12. There are [many ways to conditional selection of rows](https://www.geeksforgeeks.org/selecting-rows-in-pandas-dataframe-based-on-conditions/), but here we opt to use the information that we need all blocks with a value smaller than 11."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last block here is 12: \n",
      " 947    12\n",
      "948    12\n",
      "949    12\n",
      "950    12\n",
      "951    12\n",
      "Name: block, dtype: int64 \n",
      "\n",
      "Here the last block should be 10: \n",
      " 811    10\n",
      "812    10\n",
      "813    10\n",
      "814    10\n",
      "815    10\n",
      "Name: block, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Here the last blocks should be 12, lets check by printing the last 5 rows of the block column using the tail function\n",
    "print(\"The last block here is 12: \\n\", df_trim[\"block\"].tail(5), \"\\n\")\n",
    "\n",
    "# Conditionally select rows based on if the value in the \"block\" column is lower than 11\n",
    "df_trim_blocks = df_trim[df_trim['block'] < 11]\n",
    "\n",
    "# Check to see if the last block is now 10 instead of 12\n",
    "print(\"Here the last block should be 10: \\n\", df_trim_blocks[\"block\"].tail(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly, it's a bit confusing that we have only two subjects, but they are called number 3 and 4, instead of 1 and 2. Let's fix that by replacing subject 3 with subject 1, and subject 4 with subject 2. We can use the replace function of Pandas to achieve this. Then, with the pandas *unique* function we can verify that the subject numbers have been changed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 2]\nCategories (2, int64): [1, 2]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 3 with 1 in subject_nr column\n",
    "df_trim_blocks['subject_nr'] = df_trim_blocks['subject_nr'].replace(3, 1)\n",
    "\n",
    "# Replace 4 with 2 in subject_nr column\n",
    "df_trim_blocks['subject_nr'] = df_trim_blocks['subject_nr'].replace(4, 2)\n",
    "\n",
    "# Print out all unique values in subject_nr column, should be 1 and 2\n",
    "df_trim_blocks['subject_nr'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see what kind of data we are dealing with. The \"session\" column tells us whether the trial was in the \"lowswitch\" or \"highswitch\" condition. This means that we should see less task-switch trials in the \"lowswitch\" than in the \"highswitch\" condition. To check this, we can use the [pivot table](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html) function from pandas. Let's check:\n",
    "\n",
    "> **Note**: We will be using the pandas pivot table for most of tutorial. Be aware however that all of this could also be accomplished with the pandas groupby function. Take a look [here](https://levelup.gitconnected.com/pivot-tables-in-pandas-7b672e6d8f47) for more information on the pivot table and the difference between pivot table and groupby"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "task_transition_type  task-repetition  task-switch\nsession                                           \nhighswitch                         82          248\nlowswitch                         245           85",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>task_transition_type</th>\n      <th>task-repetition</th>\n      <th>task-switch</th>\n    </tr>\n    <tr>\n      <th>session</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>highswitch</th>\n      <td>82</td>\n      <td>248</td>\n    </tr>\n    <tr>\n      <th>lowswitch</th>\n      <td>245</td>\n      <td>85</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piv_task_transition_exp = df_trim_blocks.pivot_table(\n",
    "    index=['session'], # Index on session\n",
    "    columns='task_transition_type', # Group on 'task_transition_type'\n",
    "    aggfunc='size') # Function to aggregate columns on, here we specify \"size\"\n",
    "\n",
    "# Print out the pivot table\n",
    "piv_task_transition_exp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hmmm...doesn't balance exactly but it's close. It is always good practice to check if the trials count is what you expected. This experiment had a quite complex counterbalancing structure, since the researchers had to counterbalance:\n",
    "- Amount of congruent/incongruent trials\n",
    "- Amount of parity/magnitude trials\n",
    "- Amount of congruent-switch/congruent-repetition trials\n",
    "\n",
    "All whilst keeping the task-repetition/task-switch rate to 25/75 or 75/25 (depending on the session).\n",
    "Thereby also keeping into account that the first trial of each block does not count as either repetition or switch trial. In complex structures like this, sometimes you cannot aim for perfect counterbalancing, but you can aim for \"as good as possible\" (hence the slight discrepancy in the pivot table above). Let's see if we can use a bit more complex pivot table to get a clearer picture if all of this worked out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "            congruent  incongruent  congruency-repetition  congruency-switch  \\\nsubject_nr                                                                     \n1                 167          173                    166                164   \n2                 172          168                    163                167   \n\n            magnitude  parity  task-repetition  task-switch  \nsubject_nr                                                   \n1                 172     168              245           85  \n2                 168     172               82          248  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>congruent</th>\n      <th>incongruent</th>\n      <th>congruency-repetition</th>\n      <th>congruency-switch</th>\n      <th>magnitude</th>\n      <th>parity</th>\n      <th>task-repetition</th>\n      <th>task-switch</th>\n    </tr>\n    <tr>\n      <th>subject_nr</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>167</td>\n      <td>173</td>\n      <td>166</td>\n      <td>164</td>\n      <td>172</td>\n      <td>168</td>\n      <td>245</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>172</td>\n      <td>168</td>\n      <td>163</td>\n      <td>167</td>\n      <td>168</td>\n      <td>172</td>\n      <td>82</td>\n      <td>248</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piv_cong = df_trim_blocks.pivot_table(\n",
    "    index=['subject_nr'],\n",
    "    columns=['congruency_type'],\n",
    "    aggfunc='size') # Function to aggregate columns on, here we specify \"size\"\n",
    "\n",
    "piv_cong_transition = df_trim_blocks.pivot_table(\n",
    "    index=['subject_nr'],\n",
    "    columns=['congruency_transition_type'],\n",
    "    aggfunc='size') # Function to aggregate columns on, here we specify \"size\"\n",
    "\n",
    "piv_task = df_trim_blocks.pivot_table(\n",
    "    index=['subject_nr'],\n",
    "    columns=['task_type'],\n",
    "    aggfunc='size') # Function to aggregate columns on, here we specify \"size\"\n",
    "\n",
    "piv_task_transition = df_trim_blocks.pivot_table(\n",
    "    index=['subject_nr'],\n",
    "    columns='task_transition_type',\n",
    "    aggfunc='size') # Function to aggregate columns on, here we specify \"size\"\n",
    "\n",
    "# Add all dataframes to a list\n",
    "dfs = [piv_cong, piv_cong_transition, piv_task, piv_task_transition]\n",
    "\n",
    "# Merge the dataframes, axis=1 defines that the new dataframes should be added as columns instead of new rows\n",
    "pd.concat(dfs, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are repeating quite a lot of code. Whenever you notice that happen, you can probably shorten the code. Let's try it out:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "            magnitude  parity  congruent  incongruent  task-repetition  \\\nsubject_nr                                                               \n1                 172     168        167          173              245   \n2                 168     172        172          168               82   \n\n            task-switch  congruency-repetition  congruency-switch  \nsubject_nr                                                         \n1                    85                    166                164  \n2                   248                    163                167  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>magnitude</th>\n      <th>parity</th>\n      <th>congruent</th>\n      <th>incongruent</th>\n      <th>task-repetition</th>\n      <th>task-switch</th>\n      <th>congruency-repetition</th>\n      <th>congruency-switch</th>\n    </tr>\n    <tr>\n      <th>subject_nr</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>172</td>\n      <td>168</td>\n      <td>167</td>\n      <td>173</td>\n      <td>245</td>\n      <td>85</td>\n      <td>166</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>168</td>\n      <td>172</td>\n      <td>172</td>\n      <td>168</td>\n      <td>82</td>\n      <td>248</td>\n      <td>163</td>\n      <td>167</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the columns we want to check\n",
    "columns_to_check = ['task_type', 'congruency_type',\n",
    "                    'task_transition_type', 'congruency_transition_type']\n",
    "\n",
    "# Make an empty list so we can populate this later\n",
    "dfs = []\n",
    "\n",
    "# Loop over columns_to_check and make a new pivot table for each column\n",
    "for column in columns_to_check: # Loops over \"columns_to_check\"\n",
    "    piv = df_trim_blocks.pivot_table(\n",
    "        index=['subject_nr'],\n",
    "        columns=[column], # The for-loop inserts a new column here on every iteration\n",
    "        aggfunc='size') # Function to aggregate columns on, here we specify \"size\"\n",
    "\n",
    "    # Append the pivot table to our \"dfs\" list (which was empty initially)\n",
    "    dfs.append(piv)\n",
    "\n",
    "# Merge the dataframes that are in the \"dfs\" list\n",
    "pd.concat(dfs, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nice. It's cleaner and also way easier to change this code if you want to check another column for example. The counterbalancing looks good enough.\n",
    "\n",
    "Now we'll do some first checks on whether the results are what we expect. Let's first remove all the incorrect trials, we aren't interested in those at the moment."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "    subject_nr  block     session congruency_transition_type congruency_type  \\\n1            1      1   lowswitch          congruency-switch       congruent   \n2            1      1   lowswitch      congruency-repetition       congruent   \n3            1      1   lowswitch          congruency-switch     incongruent   \n4            1      1   lowswitch      congruency-repetition     incongruent   \n5            1      1   lowswitch      congruency-repetition     incongruent   \n..         ...    ...         ...                        ...             ...   \n810          2     10  highswitch      congruency-repetition       congruent   \n811          2     10  highswitch          congruency-switch     incongruent   \n812          2     10  highswitch      congruency-repetition     incongruent   \n814          2     10  highswitch          congruency-switch       congruent   \n815          2     10  highswitch      congruency-repetition       congruent   \n\n    correct  response_time task_transition_type  task_type response  \n1         1            707          task-switch  magnitude        a  \n2         1            856          task-switch     parity        a  \n3         1            868      task-repetition     parity        a  \n4         1           1079          task-switch  magnitude        a  \n5         1            819      task-repetition  magnitude        a  \n..      ...            ...                  ...        ...      ...  \n810       1            321          task-switch     parity    num_6  \n811       1            844          task-switch  magnitude        a  \n812       1            675          task-switch     parity    num_6  \n814       1           1354          task-switch  magnitude        a  \n815       1            506          task-switch     parity        a  \n\n[599 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_nr</th>\n      <th>block</th>\n      <th>session</th>\n      <th>congruency_transition_type</th>\n      <th>congruency_type</th>\n      <th>correct</th>\n      <th>response_time</th>\n      <th>task_transition_type</th>\n      <th>task_type</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>lowswitch</td>\n      <td>congruency-switch</td>\n      <td>congruent</td>\n      <td>1</td>\n      <td>707</td>\n      <td>task-switch</td>\n      <td>magnitude</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>lowswitch</td>\n      <td>congruency-repetition</td>\n      <td>congruent</td>\n      <td>1</td>\n      <td>856</td>\n      <td>task-switch</td>\n      <td>parity</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>lowswitch</td>\n      <td>congruency-switch</td>\n      <td>incongruent</td>\n      <td>1</td>\n      <td>868</td>\n      <td>task-repetition</td>\n      <td>parity</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>lowswitch</td>\n      <td>congruency-repetition</td>\n      <td>incongruent</td>\n      <td>1</td>\n      <td>1079</td>\n      <td>task-switch</td>\n      <td>magnitude</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>1</td>\n      <td>lowswitch</td>\n      <td>congruency-repetition</td>\n      <td>incongruent</td>\n      <td>1</td>\n      <td>819</td>\n      <td>task-repetition</td>\n      <td>magnitude</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>810</th>\n      <td>2</td>\n      <td>10</td>\n      <td>highswitch</td>\n      <td>congruency-repetition</td>\n      <td>congruent</td>\n      <td>1</td>\n      <td>321</td>\n      <td>task-switch</td>\n      <td>parity</td>\n      <td>num_6</td>\n    </tr>\n    <tr>\n      <th>811</th>\n      <td>2</td>\n      <td>10</td>\n      <td>highswitch</td>\n      <td>congruency-switch</td>\n      <td>incongruent</td>\n      <td>1</td>\n      <td>844</td>\n      <td>task-switch</td>\n      <td>magnitude</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>812</th>\n      <td>2</td>\n      <td>10</td>\n      <td>highswitch</td>\n      <td>congruency-repetition</td>\n      <td>incongruent</td>\n      <td>1</td>\n      <td>675</td>\n      <td>task-switch</td>\n      <td>parity</td>\n      <td>num_6</td>\n    </tr>\n    <tr>\n      <th>814</th>\n      <td>2</td>\n      <td>10</td>\n      <td>highswitch</td>\n      <td>congruency-switch</td>\n      <td>congruent</td>\n      <td>1</td>\n      <td>1354</td>\n      <td>task-switch</td>\n      <td>magnitude</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>815</th>\n      <td>2</td>\n      <td>10</td>\n      <td>highswitch</td>\n      <td>congruency-repetition</td>\n      <td>congruent</td>\n      <td>1</td>\n      <td>506</td>\n      <td>task-switch</td>\n      <td>parity</td>\n      <td>a</td>\n    </tr>\n  </tbody>\n</table>\n<p>599 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correct = df_trim_blocks[df_trim_blocks['correct'] == 1]\n",
    "df_correct"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "  We expect people to be slower when they have to switch from task, in comparison to when they can do the same task as on the previous trial. This is what we call **switch cost**. To show this in a table-format, we can again use the pivot_table function from pandas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "task_transition_type  task-repetition  task-switch\nsubject_nr                                        \n1                                 750          888\n2                                 638          675",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>task_transition_type</th>\n      <th>task-repetition</th>\n      <th>task-switch</th>\n    </tr>\n    <tr>\n      <th>subject_nr</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>750</td>\n      <td>888</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>638</td>\n      <td>675</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check switch costs\n",
    "switch_table = pd.pivot_table(\n",
    "    df_correct,\n",
    "    values=\"response_time\", # The value that will be summarized\n",
    "    index=[\"subject_nr\"], # The rows to summarize over\n",
    "    columns=[\"task_transition_type\"], # The columns to summarize over\n",
    "    aggfunc=np.mean, # Calculate the mean response time per subject per task type\n",
    ")\n",
    "\n",
    "# Print out the pivot table, and change it to \"int\" so we only have whole numbers\n",
    "switch_table.astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is pretty clear that task-switch trials are slower than task-repeat trials, but we can make it even clearer by showing the difference between the two columns. We can make a new column, and input in that column the difference between the task-switch trials and task-repeat trials:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "task_transition_type  task-repetition  task-switch  switch cost\nsubject_nr                                                     \n1                                 750          888          138\n2                                 638          675           37",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>task_transition_type</th>\n      <th>task-repetition</th>\n      <th>task-switch</th>\n      <th>switch cost</th>\n    </tr>\n    <tr>\n      <th>subject_nr</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>750</td>\n      <td>888</td>\n      <td>138</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>638</td>\n      <td>675</td>\n      <td>37</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do some arithmetics: subtract task-repetition from the task-switch column\n",
    "switch_table['switch cost'] = switch_table['task-switch'] - switch_table['task-repetition']\n",
    "\n",
    "# Print out as int to get whole numbers\n",
    "switch_table.astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly, you can use the handy function *describe* to get a quick peek at the response times."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "count     599\nmean      725\nstd       233\nmin       124\n25%       550\n50%       656\n75%       876\nmax      1444\nName: response_time, dtype: int32"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the \"describe\" function on the \"response_time\" column, and change the output to \"int\"\n",
    "df_correct['response_time'].describe().astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What we've done here is just a subset of the myriad of possibilities how you can change your dataframe in a way that is tidy and gives you a better overview of what you're dealing with. [This cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) gives a nice overview of the things we discussed and more! Use the cheat sheet for the following exercises.\n",
    "\n",
    "> **Note:** The developers of OpenSesame have also created a Python package for working with column-based and continuous data, called [DataMatrix](http://pydatamatrix.eu/0.15/index/). It's similar to the Pandas package we've been working with in this tutorial, but has some crucial differences in syntax. We have opted for the more versatile and widely used Pandas package, but be aware that the OpenSesame website and tutorials can sometimes refer to DataMatrixes instead of DataFrames."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly, it's important to know how to save your cleaned dataframe ofcourse! Here we save it as a csv file, using the pandas to_csv function:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "df_trim_blocks.to_csv('../11_plotting/data/df_cleaned.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercises\n",
    "\n",
    "### Exercise 1. Correct versus incorrect trials\n",
    "We've removed incorrect trials from our experiment, and looked at the switch cost effect after. However, we should be aware that there is a difference in how many incorrect trials there are per condition. Show the amount of correct/incorrect trials per task_transition_type using a pivot table. Then, show the mean reaction time of correct/incorrect trials per task_transition_type using a second pivot table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Pivot table count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Pivot table mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 2. Remove rows based on two conditions\n",
    "Next to removing incorrect trials from a dataframe, an often done dataframe manipulation is to remove outliers from your dataframe. These can be trials where participants where unrealistically quick, or just too slow to test the effect you are interested in.\n",
    "\n",
    "From the dataframe with correct trials only, remove all trials that have a reaction time below 400ms and above 1000ms. Use a conditional selection of rows, and use only one line of code."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# df_correct"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 3. Outlier removal methods\n",
    "What we did in exercise 2 was an outlier removal, though it was a pretty arbitrary one. There are plenty of outlier removal methods that are more objective. Find two outlier methods, and specify them below with a short explanation. One outlier method should be suitable for *normally distributed data*, whilst the other method should be suitable for *non-normally distributed data*.\n",
    "\n",
    "> **Hint:** In the next exercise you will have to apply the outlier methods. Therefore, search for outlier methods that you can easily implement in Python/Pandas (e.g. by simply searching for Python/Pandas implementations of outlier methods)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Answer to exercise 3*\n",
    "Outlier method for normally distributed data:\n",
    "\n",
    "Outlier method for non-normally distributed data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 4. Implementing the outlier removal methods\n",
    "Apply the two outlier methods to the dataframe with the correct responses, and save the resulting dataframe. Do this by:\n",
    "(1) Writing down what the cutoff values are for the outliers (you will need this later)\n",
    "(1) Identifying the rows that fall out of your outlier range\n",
    "(2) Making a new column called \"outlier\" where you mark the rows with outlier values with 1, and all the other rows with 0\n",
    "(3) Saving the new dataframe. If you don't know the command to save, search on the internet for \"save csv pandas\" or something similar. You will need the dataframe in the next session!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Outlier method one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Outlier method two"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
